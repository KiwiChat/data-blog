---
title: "Testing Symmetry on Contingency Tables from Paired Measurements: McNemar's Test"
author: Matthias Döring
description: "McNemar's test is a simple test for for checking whether pairwise measurements from two categories are independent. Here, I investigate the properties of the test and how it is used in R."
date: '2018-10-20'
categories:
  - statistical test
tags:
  - matched data
  - R
---



<p>McNemar’s test is a non-parametric test for contingency tables that arise from paired measurements. In contrast to the chi-squared test, which is a test for independence, McNemar’s test is a test for symmetry (also called marginal homogeneity). Still, McNemar’s test is related to the chi-squared test because its test static also follows a chi-squared distribution. <!--more--></p>
<div id="paired-categorical-data-from-two-classifiers" class="section level2">
<h2>Paired categorical data from two classifiers</h2>
<p>A typical example for paired categorical measurements arises when one wants to identify whether two classifiers yield similar predictions for identical sets of observations. In this case, the predictions relate to the same measurements and are therefore paired. Assume there are two class labels, 0 and 1.</p>
<pre class="r"><code>y_hat1 &lt;- c(rep(0, 10), rep(1,5), rep(0,5))
y_hat2 &lt;- c(rep(0, 7), rep(1,3), rep(rep(1,5)), rep(1,5))
df &lt;- data.frame(Y_Hat1 = y_hat1, Y_Hat2 = y_hat2)
print(df)</code></pre>
<pre><code>##    Y_Hat1 Y_Hat2
## 1       0      0
## 2       0      0
## 3       0      0
## 4       0      0
## 5       0      0
## 6       0      0
## 7       0      0
## 8       0      1
## 9       0      1
## 10      0      1
## 11      1      1
## 12      1      1
## 13      1      1
## 14      1      1
## 15      1      1
## 16      0      1
## 17      0      1
## 18      0      1
## 19      0      1
## 20      0      1</code></pre>
</div>
<div id="construction-of-contingency-table" class="section level2">
<h2>Construction of contingency table</h2>
<p>To construct the contingency table, we have to find the number of agreements and disagreements between the classifiers. There are four possibilities for this:</p>
<ul>
<li>Both classifiers output class 0 (0/0)</li>
<li>Classifier 1 outputs class 0 and classifier 2 outputs class 1 (0/1)</li>
<li>Classifier 1 outputs class 1 and classifier 2 outputs class 0 (1/0)</li>
<li>Both classifiers output class 1 (1/1)</li>
</ul>
<pre class="r"><code>tab &lt;- xtabs(data = df)
print(tab)</code></pre>
<pre><code>##       Y_Hat2
## Y_Hat1 0 1
##      0 7 8
##      1 0 5</code></pre>
<p>The contingency table shows that there is a deviation between the classifiers. When the first classifier predicts class 0, the second classifier often predicts class 1 (8 times).</p>
</div>
<div id="mcnemars-test" class="section level2">
<h2>McNemar’s test</h2>
<p>Since McNemar’s test assumes marginal homogeneity, it is concerned only with differences between those dichotomous outcomes where there is a disagreement. For our classifier example, this means that the test considers only the frequencies in the cells were they don’t agree (0/1 and 1/0).</p>
<p>To formalize this, assume a contingency table of the following form:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Second Classifier: 0</th>
<th align="left">Second classifier: 1</th>
<th align="left">Marginal</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">First Classifier: 0</td>
<td align="left">a</td>
<td align="left">b</td>
<td align="left">a + b</td>
</tr>
<tr class="even">
<td align="left">First classifier: 1</td>
<td align="left">c</td>
<td align="left">d</td>
<td align="left">c + d</td>
</tr>
<tr class="odd">
<td align="left">Marginal</td>
<td align="left">a + c</td>
<td align="left">b + d</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Further, let <span class="math">\(p_a\)</span>, <span class="math">\(p_b\)</span>, <span class="math">\(p_c\)</span>, and <span class="math">\(p_c\)</span> indicate the probabilities for the individual cells. The assumption of marginal homogeneity means that <span class="math">\(p_a + p_c = p_a + p_b\)</span> and <span class="math">\(p_b + p_d = p_c + p_d\)</span>. Thus, <span class="math">\(p_a\)</span> and <span class="math">\(p_d\)</span> don’t provide any information and the null hypothesis is <span class="math">\(p_b = p_c\)</span>, while the alternative is <span class="math">\(p_b \neq p_c\)</span>.</p>
<p>The test statistic is</p>
<p><span class="math">\[\chi^2 =\frac{(b - c)^2}{b+c}\,.\]</span></p>
<p>Since the test statistic has a <span class="math">\(\chi^2\)</span> distribution with 1 degree of freedom, McNemar’s test should only be applied if <span class="math">\(b +c\)</span> is sufficiently large (e.g. <span class="math">\(b + c &gt; 25\)</span>). Otherwise, an <a href="https://cran.r-project.org/web/packages/exact2x2/index.html">exact version of McNemar’s test</a> should be considered.</p>
<div id="performing-mcnemars-test-in-r" class="section level3">
<h3>Performing McNemar’s test in R</h3>
<p>McNemar’s test can be performed by providing the contingency table as an argument to <code>mcnemar.test</code>:</p>
<pre class="r"><code>mc.result &lt;- mcnemar.test(tab)
print(mc.result$p.value)</code></pre>
<pre><code>## [1] 0.01332833</code></pre>
<p>Here, the p-value indicates a significant result at the 5% level. Thus, we reject the null hypothesis and can conclude that the two classifiers make considerable different predictions.</p>
</div>
</div>
