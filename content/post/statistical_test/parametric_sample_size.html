---
title: "Parametric Testing: How Many Samples Do I Need?"
author: Matthias Döring
date: '2018-10-17'
thumbnail: "post/statistical_test/parametric_sample_size_cover.png"
categories:
  - statistical test
tags:
  - parametric test
  - sample size
  - kurtosis
  - infinite variance
  - assumptions
  - t-test
  - central limit theorem
---



<p>Parametric tests are subject to assumptions about the properties of the data. For example, Student’s t-test is a well-known parametric test that assumes that sample means have a normal distribution. Due to the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a>, the test can be also applied to measurements that are not normally distributed if the sample size is sufficient. Here, we will investigate the approximate number of samples that are necessary for the t-test to be valid.</p>
<!--more-->
<div id="fitting-normal-distributions-to-sampled-means" class="section level2">
<h2>Fitting normal distributions to sampled means</h2>
<p>To investigate the number of samples that are necessary to satisfy the requirements for Student’s t-test, we iterate over various sample sizes. For each sample size, we draw samples from several distributions. Then, the means of the samples are calculated and a normal distribution is fitted to the distribution of the means. In each iteration, we record the log-likelihood describing how well the normal distribution fits the sampled means. We’ll consider sampled means to have approached the normal distribution when the log likelihood becomes positive.</p>
<pre class="r"><code>require(MASS)
require(reshape2)
require(ggplot2)
# set seed to ensure that results are reproducible
set.seed(5)
nbr.samples &lt;- 500
sample.sizes &lt;- c(5, 10, 15, 20, 50, 100, 1000, 5000)
result &lt;- NULL
initial.means &lt;- NULL
norm.means &lt;- list()
for (i in seq_along(sample.sizes)) {
    sample.size &lt;- sample.sizes[i]
    beta.data &lt;- sapply(rep(sample.size, nbr.samples), rbeta, 1,5)
    norm.data &lt;- sapply(rep(sample.size,nbr.samples),rnorm)
    chi.data &lt;- sapply(rep(sample.size,nbr.samples),rchisq,df=1)
    pois.data &lt;- sapply(rep(sample.size,nbr.samples),rpois, lambda = 5)
    student.data &lt;- sapply(rep(sample.size, nbr.samples), rt, df = 1)
    all.data &lt;- list(&quot;Beta&quot; = beta.data, &quot;Normal&quot; = norm.data, &quot;Chi&quot; = chi.data, &quot;Poisson&quot; = pois.data, &quot;Student&quot; = student.data)
    means &lt;- lapply(all.data, colMeans)
    # store initial mean distribution for visualization
    if (i == 1) {
        initial.means &lt;- means
    }
    logliks &lt;- lapply(means, function(x) fitdistr(x, densfun = &quot;normal&quot;)$loglik)
    positive.lik &lt;- names(logliks)[which(logliks &gt; 0)]
    positive.lik &lt;- positive.lik[!positive.lik  %in% names(norm.means)]
    # store as first normal distribution for visualization
    norm.means[positive.lik] &lt;- means[positive.lik]
    result &lt;- rbind(result, data.frame(&quot;Sample_Size&quot; = sample.size, logliks))
}</code></pre>
</div>
<div id="log-likelihoods-of-fits" class="section level2">
<h2>Log likelihoods of fits</h2>
<p>Investigating the results, we can see that some distributions seem to approach the normal distribution faster than others:</p>
<pre class="r"><code>print(result)</code></pre>
<pre><code>##   Sample_Size      Beta     Normal        Chi    Poisson   Student
## 1           5  694.9139 -299.81161 -496.33474 -702.94076 -1971.203
## 2          10  823.0384 -126.68806 -297.08253 -515.18702 -3806.447
## 3          15  909.4417  -30.63266 -199.77525 -455.64737 -2119.944
## 4          20 1045.1414   46.45709 -136.21868 -375.75690 -2263.025
## 5          50 1235.7655  278.66189   84.44694 -117.56140 -3427.721
## 6         100 1397.7265  443.81523  281.68706   47.87537 -2178.871
## 7        1000 1996.2198 1019.70692  845.26837  619.25871 -3636.674
## 8        5000 2398.4267 1402.41433 1260.47873 1018.24454 -3231.983</code></pre>
<p>According to positive log likelihoods, the beta distribution yields normally distributed means already at a sample size of 5. Normal, chi-squared, and Poisson distributions yield normally distributed means at sample sizes of 20, 50, and 100, respectively. Finally, the means of Student’s distribution never become normal since the distribution with one degree of freedom has infinite kurtosis such that the central limit theorem does not hold.</p>
</div>
<div id="verifying-the-log-likelihood-criterion" class="section level2">
<h2>Verifying the log-likelihood criterion</h2>
<p>As verification of the results, let’s plot the histograms at the sample size of 5 and at the sample size where the mean distribution became normal:</p>
<pre class="r"><code>plot.means &lt;- function(means) {
    mean.df &lt;- as.data.frame(means)
    mean.df &lt;- melt(mean.df, id.vars = NULL)
    ggplot(mean.df, aes(x = value)) + geom_histogram(bins = 100) + facet_wrap(.~variable, scales = &quot;free_x&quot;)
}
plot.means(initial.means)</code></pre>
<p><img src="/post/statistical_test/parametric_sample_size_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>plot.means(norm.means)</code></pre>
<p><img src="/post/statistical_test/parametric_sample_size_files/figure-html/unnamed-chunk-3-2.png" width="672" /></p>
<p>These results indicate that the log-likelihood criterion is a sufficient proxy for normality. Note, however, that from visual inspection, the initial beta distribution of means does not seem <em>more normal</em> than the one arising from the normal distribution. So this result may be taken with a grain of salt. Looking at Student’s t-distribution, we can see why it its means are not normally distributed:</p>
<pre class="r"><code>round(quantile(means$Student), 2)</code></pre>
<pre><code>##      0%     25%     50%     75%    100% 
## -495.61   -0.95    0.00    0.98 3422.66</code></pre>
<p>For some of the samples, the mean distribution has extreme outliers at both tails of the distribution.</p>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>The results of these experiments indicate that Student’s t-test should definitely be avoided for sample sizes smaller than 20. The assumptions of the test seem to be met for most distribution when the sample size is at least 100. So, it turns out I was correct in having a bad feeling when <a href="/post/statistical_test/signed_wilcox_rank_test/">I recently applied the t-test on only 10 samples</a>.</p>
<p>To conclude, it is particularly advisable to check the distribution of the measurements for sample sizes below 100. Since the central limit theorem does not hold for distributions with infinite variance, it is also reasonable to verify the distribution of measurements for large sample sizes in order to exclude the possibility of such a distribution. As we have seen here, measurements distributed according to the t-distribution with one degree of freedom did not fulfill the assumption of the test even at a sample size of 5000.</p>
<p>So, at what sample size do you feel confident using parametric tests such as Student’s t-test? When do you investigate the distribution of the data?</p>
<p>This post was inspired by <a href="https://stats.stackexchange.com/questions/9573/t-test-for-non-normal-when-n50">this discussion at Stack Exchange</a>. A further discussion of infinite variance can be found <a href="https://stats.stackexchange.com/questions/94402/what-is-the-difference-between-finite-and-infinite-variance">in another Stack Exchange thread</a>.</p>
</div>
