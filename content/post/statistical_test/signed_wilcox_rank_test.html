---
title: "Wilcoxon Signed Rank Test vs Paired Student's t-test"
author: Matthias Döring
date: '2018-10-16'
description: "Use a paired Student's t-test or a Wilcoxon signed rank test? Find out when to use which statistical test!"
thumbnail: "post/statistical_test/signed_wilcox_rank_test_cover.png"
categories:
  - statistical test
tags:
  - non-parametric test
  - parametric test
  - matched data
  - R
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>In this post, we will explore tests for comparing two groups of dependent (i.e. paired) quantitative data: the Wilcoxon signed rank test and the paired Student’s t-test. The critical difference between these tests is that the test from Wilcoxon is a non-parametric test, while the t-test is a parametric test. In the following, we will explore the ramifications of this difference.
<!--more--></p>
<div id="the-sleep-data-set" class="section level2">
<h2>The sleep data set</h2>
<p>Let’s consider the sleep data set. The data set contrasts the effect of two soporific drugs (aka sleeping pills) by providing the change in the number of hours slept after taking the drug compared to a baseline:</p>
<pre class="r"><code>data(sleep) # load the sleep data set
print(sleep)</code></pre>
<pre><code>##    extra group ID
## 1    0.7     1  1
## 2   -1.6     1  2
## 3   -0.2     1  3
## 4   -1.2     1  4
## 5   -0.1     1  5
## 6    3.4     1  6
## 7    3.7     1  7
## 8    0.8     1  8
## 9    0.0     1  9
## 10   2.0     1 10
## 11   1.9     2  1
## 12   0.8     2  2
## 13   1.1     2  3
## 14   0.1     2  4
## 15  -0.1     2  5
## 16   4.4     2  6
## 17   5.5     2  7
## 18   1.6     2  8
## 19   4.6     2  9
## 20   3.4     2 10</code></pre>
<p><em>extra</em> indicates the increase/decrease (positive/negative values) in sleep compared to the baseline measurement, <em>group</em> denotes the drug, and <em>ID</em> gives the patient ID. To make this clearer, I’ll rename <em>group</em> to <em>drug</em>:</p>
<pre class="r"><code>colnames(sleep)[which(colnames(sleep) == &quot;group&quot;)] &lt;- &quot;drug&quot;</code></pre>
<p>Note that the sleep data set contains two measurements for every patient. Thus, it is appropriate for showcasing paired tests such as the ones we are dealing with.</p>
</div>
<div id="what-are-we-testing-for" class="section level2">
<h2>What are we testing for?</h2>
<p>Assume we are working in a pharmaceutical company and these are the data that were just obtained from a clinical trial. Now, we must decide which of the two drugs you should go forward with for market release. A reasonable way of selecting the drug would be to identify the drug that performs better. More specifically, the question is the following: is one of the drugs associated with greater values of <em>extra</em> than the other drug?</p>
<p>To get an intuition about the effectiveness of the two drugs, let’s plot their corresponding values:</p>
<p><img src="/post/statistical_test/signed_wilcox_rank_test_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The plot shows that the median increase in sleep time of drug 1 is close to 0, while the median increase for drug 2 is close to 2 hours. So, based on these data it seems that drug 2 is more effective than drug 1. However, we still need to determine whether our finding is statistically significant.</p>
<div id="the-null-hypothesis" class="section level3">
<h3>The null hypothesis</h3>
<p>The null hypothesis of the test is that there isn’t any difference in the extra sleep time between the two drugs. Since we want to find out whether drug 2 outperforms drug 1, we do not need a two-tailed test (testing whether any of the drugs has superior performance), but a one-tailed test. Thus, the alternative of the null hypothesis is that drug 2 is associated with greater values of <em>extra</em> than drug 1.</p>
</div>
</div>
<div id="wilcoxon-signed-rank-test" class="section level2">
<h2>Wilcoxon Signed Rank Test</h2>
<p>The Wilcoxon signed rank test uses the sum of the signed ranks as the test statistic <span class="math inline">\(W\)</span>:
<span class="math display">\[W=\sum _{{i=1}}^{{N}}[\operatorname{sgn}(x_{{2,i}}-x_{{1,i}})\cdot R_{i}]\]</span>
Here, the <span class="math inline">\(i\)</span>-th of <span class="math inline">\(N\)</span> measurement pairs is indicated by <span class="math inline">\(x_i = (x_{1,i}, x_{2,i})\)</span> and <span class="math inline">\(R_{i}\)</span> denotes the rank of the pair. The rank simply represents the position of an observation in an ordered list of <span class="math inline">\(|x_{2,i} - x_{1,i}|\)</span>. The inuition of the test statistic is that pairs with large absolute differences will have large ranks <span class="math inline">\(R_{i}\)</span>. Thus, these pairs are the determining factors of <span class="math inline">\(W\)</span>, while pairs exhibiting small absolute differences have a low <span class="math inline">\(R_{i}\)</span> and therefore little influence on the outcome of the test. Since the test statistic is based on ranks rather than the measurements themselves, the Wilcoxon signed rank test can be thought of as testing for shifts in median values between two groups.</p>
<p>To perform the test in R, we can use the <code>wilcox.test</code> function. However, we have to explicitly set the <em>paired</em> argument to indicate that we are dealing with matched observations. To specify the one-tailed test, we set the <em>alternative</em> argument to <em>greater</em>. In this way, the alternative of the test is whether drug 2 is associated with larger increases in sleep duration than drug 1.</p>
<pre class="r"><code>x &lt;- sleep$extra[sleep$drug == 2]
y &lt;- sleep$extra[sleep$drug == 1]
res &lt;- wilcox.test(x, y, paired = TRUE, 
                   alternative = &quot;greater&quot;)</code></pre>
<pre><code>## Warning in wilcox.test.default(x, y, paired = TRUE, alternative = &quot;greater&quot;):
## cannot compute exact p-value with ties</code></pre>
<pre><code>## Warning in wilcox.test.default(x, y, paired = TRUE, alternative = &quot;greater&quot;):
## cannot compute exact p-value with zeroes</code></pre>
<div id="investigating-the-warnings" class="section level3">
<h3>Investigating the warnings</h3>
<p>Before getting to the results, we should investigate the two warnings that resulted from performing the test.</p>
<div id="warning-1-ties" class="section level4">
<h4>Warning 1: ties</h4>
<p>The first warning arises because the test ranks differences in the <code>extra</code> values of pairs. If two pairs share the same difference, ties arise during ranking. We can verify this by computing the difference between the pairs</p>
<pre class="r"><code>x - y</code></pre>
<pre><code>##  [1] 1.2 2.4 1.3 1.3 0.0 1.0 1.8 0.8 4.6 1.4</code></pre>
<p>and finding that pairs 3 and 4 both share the same difference of 1.3. Why are ties a problem? The rank assigned to ties is based on the average of the ranks they span. Thus, if there are many ties, this reduces the expressiveness of the test statistic rendering the Wilcoxon test inappropriate. Since we only have a single tie here, this is not a problem.</p>
</div>
<div id="warning-2-zero-values" class="section level4">
<h4>Warning 2: zero values</h4>
<p>The second warning relates to pairs where the difference is 0. In the sleep data set, this is the case for the pair from the 5th patient (see above). Why are zeros a problem? Remember that the null hypothesis is that the differences of the pairs are centered around 0. However, observing differences where the value is exactly 0 do not give us any information for the rejection of the null. Therefore, these pairs are discarded when computing the test statistic. If this is the case for many of the pairs, the statistical power of the test would drop considerably. Again, this is not a problem for us as only a single zero value is present.</p>
</div>
</div>
<div id="investigating-the-results" class="section level3">
<h3>Investigating the results</h3>
<p>The main result of the test, is its p-value, which can be obtained via:</p>
<pre class="r"><code>res$p.value</code></pre>
<pre><code>## [1] 0.004545349</code></pre>
<p>Since the p-value is less than the 5% significance level, this means we can reject the null hypothesis. Thus, we would be inclined to accept the alternative hypothesis, which states that drug 2 outperforms drug 1.</p>
</div>
</div>
<div id="paired-students-t-test" class="section level2">
<h2>Paired Student’s t-test</h2>
<p>The paired Student’s t-test is a parametric test on the means of paired quantitative measurements from two groups. Here, parametric means that the t-test assumes that the mean difference between samples is normally distributed. The test relies on identifying whether the mean difference of measurements from the two groups, <span class="math inline">\(\bar{X}_{D}\)</span> is larger than <span class="math inline">\(\mu_D\)</span>, where <span class="math inline">\(\mu_D\)</span> is typically set to 0 in order to find if there is any difference. The test-statistic,</p>
<p><span class="math display">\[\displaystyle t={\frac {{\bar {X}}_{D}-\mu _{0}}{\frac {s_{D}}{\sqrt {n}}}},\]</span></p>
<p>is normalized using the standard deviation of differences, <span class="math inline">\(s_D\)</span>, and the number of pairs <span class="math inline">\(n\)</span>. By normalizing according to <span class="math inline">\(\frac{s_D}{\sqrt{n}}\)</span>, the test statistic regulates the value of the test statistic according to the number of samples (<span class="math inline">\(|t|\)</span> increases with more samples) and the standard deviation of differences (<span class="math inline">\(|t|\)</span> decreases if the deviation increases).</p>
<p>In R, we can perform the paired t-test with the <code>t.test</code> function. Note that <code>t.test</code> assumes that population variances are inequal. In this case, the test is also called <em>Welch’s t-test</em>. To obtain the original t-test, which assumes that the population variances are equal, we can just set the <code>equal.var</code> parameter to <code>TRUE</code>. Here, we will just use with the default setting:</p>
<pre class="r"><code>t.result &lt;- t.test(x,y, paired = TRUE, alternative = &quot;greater&quot;)
print(t.result$p.value)</code></pre>
<pre><code>## [1] 0.001416445</code></pre>
<p>Again, the p-value is less than 0.05. Thus, we would be inclined to accept the alternative hypothesis: drug 2 is associated with a greater increase in mean sleep duration than drug 1.</p>
<div id="checking-the-assumptions-of-students-t-test" class="section level3">
<h3>Checking the assumptions of Student’s t-test</h3>
<p>The t-test requires that the sample means are normally distributed. By the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a>, means of samples from a population approach a normal distribution for a sufficient number of samples. Therefore, the assumption of the t-test is met even for non-normal measurements as long as there are is a sufficient number of samples. Since the sleep data contains only 10 paired measurements, there should be reason for concern. Thus, we should check whether the diffeerences between measurements are normally distributed in order to verify whether the t-test is valid:</p>
<pre class="r"><code>diff.df &lt;- data.frame(diff = sleep$extra[sleep$drug == 1] - sleep$extra[sleep$drug == 2])
ggplot(diff.df, aes(x = diff)) + geom_histogram()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/post/statistical_test/signed_wilcox_rank_test_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Looking at the histogram, the data seem rather uniformly than normally distributed. To take a closer look, we compare the differences to the values that would be expected from a normal distribution using a <a href="https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot">Q-Q (quantile-quantile) plot</a>:</p>
<pre class="r"><code>require(car) # load car package to use &#39;qqp&#39; rather than native &#39;qqplot&#39; function</code></pre>
<pre><code>## Loading required package: car</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre class="r"><code>qqp(diff.df$diff)</code></pre>
<p><img src="/post/statistical_test/signed_wilcox_rank_test_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre><code>## [1] 9 5</code></pre>
<p>The Q-Q plot shows that the differences fit the normal model quite well, except for the heavy tails. From this, we could conclude that the assumption of the t-test is sufficiently met. Still, we’re left with a feeling of uncertainty about whether the t-test was the most appropriate choice for these data.</p>
</div>
</div>
<div id="summary-wilcoxon-signed-rank-test-vs-paired-students-t-test" class="section level2">
<h2>Summary: Wilcoxon signed rank test vs paired Student’s t-test</h2>
<p>In this analysis, both Wilcoxon signed rank test and paired Student’s t-test led to the rejection of the null hypothesis. In general, however, which test is more appropriate? The answer is, it depends on several criteria:</p>
<ul>
<li><strong>Hypothesis:</strong> Student’s t-test is a test comparing means, while Wilcoxon’s tests the ordering of the data. For example, if you are analyzing data with many outliers such as individual wealth (where few billionaires can greatly influence the result), Wilcoxon’s test may be more appropriate.</li>
<li><strong>Interpretation:</strong> Although confidence intervals can also be computed for Wilcoxon’s test, it may seem more natural to argue about the confidence interval of the mean in the t-test than the pseudomedian for Wilcoxon’s test.</li>
<li><strong>Fulfillment of assumptions:</strong> The assumptions of Student’s t-test may not be met <a href="/post/statistical_test/parametric_sample_size/">for small sample sizes</a>. In this case, it is often safer to select a non-parametric test. However, if the assumptions of the t-test are met, it has greater <a href="https://en.wikipedia.org/wiki/Power_(statistics)">statistical power</a> than Wilcoxon’s test.</li>
</ul>
<p>Due to the small sample size of the sleep data set, I’d prefer the test from Wilcoxon for these data.</p>
<p>Which test would you use? In general, would you prefer one test over the other?</p>
</div>
