---
title: "Improving Ozone Prediction 2.0"
author: Matthias DÃ¶ring
downloadRmd: true
draft: true
date: '2018-12-09T15:00:00Z'
description: ""
categories:
  - machine-learning
tags:
    - analysis
    - linear model
    - supervised learning
    - R
thumbnail: "/post/machine-learning/improving_ozone_prediction_cover.png"
---



<p>Recently, I have worked on <a href="/post/machine-learning/improving_ozone_prediction/">finding a suitable linear model for ozone prediction</a>. At that time, I did not take the longitudinal nature of the measurements into account but instead assume that all the measurements are independent of one another. However, a more reasonable assumption is that, when the ozone level was high the day before, it is likely going to be high the following day.</p>
<div id="exploring-the-temporal-nature-of-the-data" class="section level2">
<h2>Exploring the temporal nature of the data</h2>
<p>Let us load the ozone data set and divide it into test and training set:</p>
<pre class="r"><code>data(airquality)
ozone &lt;- subset(na.omit(airquality))
set.seed(123)
N.train &lt;- ceiling(0.7 * nrow(ozone))
N.test &lt;- nrow(ozone) - N.train
# ensure to take only subsequent measurements for time-series analysis:
trainset &lt;- seq_len(nrow(ozone))[1:N.train]
testset &lt;- setdiff(seq_len(nrow(ozone)), trainset)</code></pre>
<p>We are interested in finding out whether the observed value of ozone depends on the previous measurements, that is, whether</p>
<p><span class="math display">\[Pr(Y = y | X = x^1, \ldots, x^t) \neq Pr(Y = y | X = x)\]</span></p>
<p>For this purpose, we will create a new column in the ozone data set, which reflects the relative point in time:</p>
<pre class="r"><code>year &lt;- 1973 # known from data documentation
months &lt;- unique(ozone$Month)
months &lt;- c(months, max(months) + 1)
dates &lt;- sapply(paste0(year, &quot;-&quot;, months, &quot;-&quot;, &quot;01&quot;), as.Date)
days.per.month &lt;- as.numeric(diff(dates))
names(days.per.month) &lt;- unique(ozone$Month)
t &lt;- rep(NA, nrow(ozone))
for (i in seq_len(nrow(ozone))) {
    month.days &lt;- days.per.month[as.character(ozone$Month[i])]
    offset &lt;- ozone$Month[i] - min(ozone$Month)
    days.before &lt;- 0
    if (offset != 0) {
        days.before &lt;- sum(days.per.month[1:offset])
    }
    t[i] &lt;- ozone$Day[i] + days.before

}
ozone &lt;- cbind(ozone, &quot;t&quot; = t)</code></pre>
<p>Let us now plot the time trend of ozone:</p>
<pre class="r"><code>library(ggplot2)
ggplot(ozone, aes(x = t, y = Ozone)) + geom_line() +
        geom_point()</code></pre>
<p><img src="/post/machine-learning/improving_ozone_prediction_2.0_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We see that there is a temporal trend, although there are also many outliers.</p>
</div>
<div id="autocorrelation" class="section level2">
<h2>Autocorrelation</h2>
<p>Let us plot the autocorrelation to find whether the distribution is stationary.</p>
<pre class="r"><code>library(TSA)</code></pre>
<pre><code>## Loading required package: leaps</code></pre>
<pre><code>## Loading required package: locfit</code></pre>
<pre><code>## locfit 1.5-9.1    2013-03-22</code></pre>
<pre><code>## Loading required package: mgcv</code></pre>
<pre><code>## Loading required package: nlme</code></pre>
<pre><code>## This is mgcv 1.8-19. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;.</code></pre>
<pre><code>## Loading required package: tseries</code></pre>
<pre><code>## 
## Attaching package: &#39;TSA&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     acf, arima</code></pre>
<pre><code>## The following object is masked from &#39;package:utils&#39;:
## 
##     tar</code></pre>
<pre class="r"><code>acf(ozone$Ozone, lag.max = 10)</code></pre>
<p><img src="/post/machine-learning/improving_ozone_prediction_2.0_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>The autocorrelation function shows us the autocorrelation of the ozone levels for different lags. That is, for a lag of 1, this is the correlation of the ozone level at time <span class="math inline">\(t\)</span> with those at <span class="math inline">\(t-1\)</span>. The horizontal lines indicate the significance bands. The plot shows that for differences where <span class="math inline">\(t =1\)</span>, the autocorrelation is the highest and that autocorrelation does not play a role anymore when looking back more than 8 days into the past.</p>
<p>Since there is no clear trend in the autocorrelation (it is decreasing but not steadily), we conclude that there we do not need to find non-seasonal differences for stationarity.</p>
<p>Since previous measurements are correlated withe each other, we can calculate the partial autocorrelation to find the corrected correlation taking into account this propagation:</p>
<pre class="r"><code>acf(ozone$Ozone, lag.max = 10, type = &quot;partial&quot;)</code></pre>
<p><img src="/post/machine-learning/improving_ozone_prediction_2.0_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The partial autocorrelation demonstrates that most of the autocorrelation comes from the previous day and that the effect from earlier days before is negligible. Thus, an AR (autoregression) term of order 1 seems warranted.</p>
</div>
<div id="ar-and-ma-terms-do-this-in-previous-part" class="section level2">
<h2>AR and MA terms: do this in previous part!</h2>
<p>To find the AR and MA term order, we consider again the previous autocorrelation.</p>
<pre class="r"><code>acf(ozone$Ozone, lag.max = 10)</code></pre>
<p><img src="/post/machine-learning/improving_ozone_prediction_2.0_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>To model features, we will define them as</p>
<pre class="r"><code>features &lt;- c(&quot;Solar.R&quot;, &quot;Wind&quot;, &quot;Temp&quot;)</code></pre>
<p>and specify them as exogenous features in an ARMAX model:</p>
<pre class="r"><code>#library(forecast)
library(TSA)
# does not matter much which is chosen ...
# arima(0,1,1): exponential smoothing
# arima(1,0,0): stationary, autocorrelated
#A &lt;- arimax(x = ozone$Ozone[trainset], 
       #xreg = ozone[trainset,features],
        #order = c(0,1,1))
A &lt;- arimax(x = ozone$Ozone[trainset], 
       xreg = ozone[trainset,features],
        order = c(1,0,0)) # 1 AR term, no term for non-seasonal stationarity, and no term for lagged forecast errors (MA term)
# seasonal adjustment doesn&#39;t make any sense because we dont have data for multiple years
# outlier types:
# additive outlier: subsequent values are unaffected by additive outliers
# innovational outlier: initial impact, with effect lingering over the next observations.
# not feasible to predict using io specification
#A &lt;- arimax(x = ozone$Ozone[trainset], 
       #xreg = ozone[trainset,features],
        #order = c(1,0,0),
        #io = list(23, 34, 63, 77))
#A &lt;- arimax(x = ozone$Ozone[trainset], 
       #xreg = ozone[trainset,features],
        #order = c(1,0,0),
        #seasonal = c(0, 0, 1)) # moving average for season effect, doesn&#39;t help
preds.temporal &lt;- predict(A, newxreg = ozone[testset, features])</code></pre>
<div id="comparison-with-previous-model" class="section level3">
<h3>Comparison with previous model</h3>
<p>Let us load our previous model (GLM with negative binomial distribution):</p>
<pre class="r"><code>library(MASS)
get.weights &lt;- function(ozone) {
    z.scores &lt;- (ozone$Ozone - mean(ozone$Ozone)) / sd(ozone$Ozone)
    weights &lt;- exp(z.scores)
    weights &lt;- weights / mean(weights) # normalize to mean 1
    return(weights)
}
weights &lt;- get.weights(ozone)
# train weighted negative binomial model
model.nb &lt;- glm.nb(Ozone ~ Solar.R + Temp + Wind, data = ozone, subset = trainset, weights = weights)
preds.nb &lt;- predict(model.nb, newdata = ozone[testset,], type = &quot;response&quot;)</code></pre>
<p>Let us plot:</p>
<pre class="r"><code>plot.df &lt;- data.frame(&quot;Reference&quot; = ozone[testset, &quot;Ozone&quot;],
                      &quot;Forecasting&quot; = as.numeric(preds.temporal$pred),
                      &quot;Prediction&quot; = as.numeric(preds.nb),
                      &quot;t&quot; = ozone[testset, &quot;t&quot;])
library(reshape2)
p.df &lt;- melt(plot.df, &quot;t&quot;)
library(ggplot2)
p1 &lt;- ggplot(p.df, aes(x = t, y = value, colour = variable)) + 
    geom_point(alpha = 0.8) + geom_line()
p1</code></pre>
<p><img src="/post/machine-learning/improving_ozone_prediction_2.0_files/figure-html/unnamed-chunk-10-1.png" width="672" /> Let us determine the performance of both models:</p>
<pre class="r"><code>Rsquared.linear &lt;- cor(preds.nb, ozone[testset, &quot;Ozone&quot;])^2
Rsquared.temporal &lt;- cor(preds.temporal$pred, ozone[testset, &quot;Ozone&quot;])^2
print(Rsquared.linear)</code></pre>
<pre><code>## [1] 0.7676977</code></pre>
<pre class="r"><code>print(Rsquared.temporal)</code></pre>
<pre><code>## [1] 0.7569456</code></pre>
<p>We see that the prediction model slightly outperforms the forecasting model.</p>
</div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p><a href="http://people.duke.edu/~rnau/411arim.htm" class="uri">http://people.duke.edu/~rnau/411arim.htm</a> <a href="https://robjhyndman.com/hyndsight/arimax/" class="uri">https://robjhyndman.com/hyndsight/arimax/</a></p>
</div>
